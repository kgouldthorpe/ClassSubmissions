{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Smartphone Activity Detector\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Predict human activity using smartphone sensor data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n",
    "Note: This dataset has already been scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Paths\n",
    "X_training_data = os.path.join(\"..\", \"Resources\", \"Train\", \"X_train.txt\")\n",
    "y_training_data = os.path.join(\"..\", \"Resources\", \"Train\", \"y_train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data Paths\n",
    "X_testing_data = os.path.join(\"..\", \"Resources\", \"Test\", \"X_test.txt\")\n",
    "y_testing_data = os.path.join(\"..\", \"Resources\", \"Test\", \"y_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039480</td>\n",
       "      <td>-0.002131</td>\n",
       "      <td>-0.029067</td>\n",
       "      <td>-0.998348</td>\n",
       "      <td>-0.982945</td>\n",
       "      <td>-0.971273</td>\n",
       "      <td>-0.998702</td>\n",
       "      <td>-0.983315</td>\n",
       "      <td>-0.974000</td>\n",
       "      <td>-0.802537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202804</td>\n",
       "      <td>-0.603199</td>\n",
       "      <td>-0.860677</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.845092</td>\n",
       "      <td>0.180261</td>\n",
       "      <td>-0.047436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039978</td>\n",
       "      <td>-0.005153</td>\n",
       "      <td>-0.022651</td>\n",
       "      <td>-0.995482</td>\n",
       "      <td>-0.977314</td>\n",
       "      <td>-0.984760</td>\n",
       "      <td>-0.996415</td>\n",
       "      <td>-0.975835</td>\n",
       "      <td>-0.985973</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440079</td>\n",
       "      <td>-0.404427</td>\n",
       "      <td>-0.761847</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.849230</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.042271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039785</td>\n",
       "      <td>-0.011809</td>\n",
       "      <td>-0.028916</td>\n",
       "      <td>-0.996194</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.993256</td>\n",
       "      <td>-0.996994</td>\n",
       "      <td>-0.988526</td>\n",
       "      <td>-0.993135</td>\n",
       "      <td>-0.798477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430891</td>\n",
       "      <td>-0.138373</td>\n",
       "      <td>-0.491604</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848947</td>\n",
       "      <td>0.181907</td>\n",
       "      <td>-0.040826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038758</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.998241</td>\n",
       "      <td>-0.986774</td>\n",
       "      <td>-0.993115</td>\n",
       "      <td>-0.998216</td>\n",
       "      <td>-0.986479</td>\n",
       "      <td>-0.993825</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137735</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.702490</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.848164</td>\n",
       "      <td>0.185124</td>\n",
       "      <td>-0.037080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038988</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>-0.997438</td>\n",
       "      <td>-0.993485</td>\n",
       "      <td>-0.996692</td>\n",
       "      <td>-0.997522</td>\n",
       "      <td>-0.993494</td>\n",
       "      <td>-0.996916</td>\n",
       "      <td>-0.801982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074999</td>\n",
       "      <td>-0.554902</td>\n",
       "      <td>-0.844224</td>\n",
       "      <td>0.082632</td>\n",
       "      <td>-0.143439</td>\n",
       "      <td>0.275041</td>\n",
       "      <td>-0.368224</td>\n",
       "      <td>-0.849927</td>\n",
       "      <td>0.184795</td>\n",
       "      <td>-0.035326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.039480 -0.002131 -0.029067 -0.998348 -0.982945 -0.971273 -0.998702   \n",
       "1  0.039978 -0.005153 -0.022651 -0.995482 -0.977314 -0.984760 -0.996415   \n",
       "2  0.039785 -0.011809 -0.028916 -0.996194 -0.988569 -0.993256 -0.996994   \n",
       "3  0.038758 -0.002289 -0.023863 -0.998241 -0.986774 -0.993115 -0.998216   \n",
       "4  0.038988  0.004109 -0.017340 -0.997438 -0.993485 -0.996692 -0.997522   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.983315 -0.974000 -0.802537  ...  0.202804 -0.603199 -0.860677  0.053477   \n",
       "1 -0.975835 -0.985973 -0.798477  ...  0.440079 -0.404427 -0.761847 -0.118559   \n",
       "2 -0.988526 -0.993135 -0.798477  ...  0.430891 -0.138373 -0.491604 -0.036788   \n",
       "3 -0.986479 -0.993825 -0.801982  ...  0.137735 -0.366214 -0.702490  0.123320   \n",
       "4 -0.993494 -0.996916 -0.801982  ...  0.074999 -0.554902 -0.844224  0.082632   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0 -0.007435 -0.732626  0.703511 -0.845092  0.180261 -0.047436  \n",
       "1  0.177899  0.100699  0.808529 -0.849230  0.180610 -0.042271  \n",
       "2 -0.012892  0.640011 -0.485366 -0.848947  0.181907 -0.040826  \n",
       "3  0.122542  0.693578 -0.615971 -0.848164  0.185124 -0.037080  \n",
       "4 -0.143439  0.275041 -0.368224 -0.849927  0.184795 -0.035326  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training data into a dataframe\n",
    "X_train_df = pd.read_csv(\n",
    "    X_training_data, delimiter=\" \", skiprows=1, header=None)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe to a numpy array for Keras\n",
    "X_train = X_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the training labels as a dataframe\n",
    "y_train_df = pd.read_csv(y_training_data)\n",
    "\n",
    "# One-hot encode the integer labels\n",
    "# 1 WALKING\n",
    "# 2 WALKING_UPSTAIRS\n",
    "# 3 WALKING_DOWNSTAIRS\n",
    "# 4 SITTING\n",
    "# 5 STANDING\n",
    "# 6 LAYING\n",
    "# 7 STAND_TO_SIT\n",
    "# 8 SIT_TO_STAND\n",
    "# 9 SIT_TO_LIE\n",
    "# 10 LIE_TO_SIT\n",
    "# 11 STAND_TO_LIE\n",
    "# 12 LIE_TO_STAND\n",
    "\n",
    "y_train = to_categorical(y_train_df)\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3161, 561)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the testing data\n",
    "X_test_df = pd.read_csv(X_testing_data, delimiter=\" \", skiprows=1, header=None)\n",
    "X_test = X_test_df.values\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3161, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the testing labels\n",
    "y_test_df = pd.read_csv(y_testing_data)\n",
    "# One-hot encode the integer labels\n",
    "y_test = to_categorical(y_test_df)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 561 columns of the training data\n",
    "model.add(Dense(units=100, activation='relu', input_dim=561))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(units=100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7766, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output layer has 13 columns that are one-hot encoded\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using categorical_crossentropy for the loss function, the adam optimizer,\n",
    "# and add accuracy to the training metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7766 samples\n",
      "Epoch 1/60\n",
      "7766/7766 - 1s - loss: 0.7504 - accuracy: 0.6819\n",
      "Epoch 2/60\n",
      "7766/7766 - 1s - loss: 0.7510 - accuracy: 0.6807\n",
      "Epoch 3/60\n",
      "7766/7766 - 1s - loss: 0.7463 - accuracy: 0.6830\n",
      "Epoch 4/60\n",
      "7766/7766 - 1s - loss: 0.7447 - accuracy: 0.6834\n",
      "Epoch 5/60\n",
      "7766/7766 - 1s - loss: 0.7441 - accuracy: 0.6818\n",
      "Epoch 6/60\n",
      "7766/7766 - 1s - loss: 0.7444 - accuracy: 0.6810\n",
      "Epoch 7/60\n",
      "7766/7766 - 1s - loss: 0.7447 - accuracy: 0.6814\n",
      "Epoch 8/60\n",
      "7766/7766 - 1s - loss: 0.7409 - accuracy: 0.6813\n",
      "Epoch 9/60\n",
      "7766/7766 - 1s - loss: 0.7384 - accuracy: 0.6808\n",
      "Epoch 10/60\n",
      "7766/7766 - 1s - loss: 0.7352 - accuracy: 0.6819\n",
      "Epoch 11/60\n",
      "7766/7766 - 1s - loss: 0.7371 - accuracy: 0.6819\n",
      "Epoch 12/60\n",
      "7766/7766 - 1s - loss: 0.7302 - accuracy: 0.6825\n",
      "Epoch 13/60\n",
      "7766/7766 - 1s - loss: 0.7323 - accuracy: 0.6809\n",
      "Epoch 14/60\n",
      "7766/7766 - 1s - loss: 0.7277 - accuracy: 0.6828\n",
      "Epoch 15/60\n",
      "7766/7766 - 1s - loss: 0.7310 - accuracy: 0.6800\n",
      "Epoch 16/60\n",
      "7766/7766 - 1s - loss: 0.7254 - accuracy: 0.6818\n",
      "Epoch 17/60\n",
      "7766/7766 - 1s - loss: 0.7268 - accuracy: 0.6812\n",
      "Epoch 18/60\n",
      "7766/7766 - 1s - loss: 0.7215 - accuracy: 0.6828\n",
      "Epoch 19/60\n",
      "7766/7766 - 1s - loss: 0.7194 - accuracy: 0.6830\n",
      "Epoch 20/60\n",
      "7766/7766 - 1s - loss: 0.7203 - accuracy: 0.6823\n",
      "Epoch 21/60\n",
      "7766/7766 - 1s - loss: 0.7193 - accuracy: 0.6830\n",
      "Epoch 22/60\n",
      "7766/7766 - 1s - loss: 0.7188 - accuracy: 0.6818\n",
      "Epoch 23/60\n",
      "7766/7766 - 1s - loss: 0.7355 - accuracy: 0.6764\n",
      "Epoch 24/60\n",
      "7766/7766 - 1s - loss: 0.7131 - accuracy: 0.6840\n",
      "Epoch 25/60\n",
      "7766/7766 - 1s - loss: 0.7091 - accuracy: 0.6841\n",
      "Epoch 26/60\n",
      "7766/7766 - 1s - loss: 0.7097 - accuracy: 0.6825\n",
      "Epoch 27/60\n",
      "7766/7766 - 1s - loss: 0.7163 - accuracy: 0.6791\n",
      "Epoch 28/60\n",
      "7766/7766 - 1s - loss: 0.7034 - accuracy: 0.6849\n",
      "Epoch 29/60\n",
      "7766/7766 - 1s - loss: 0.7147 - accuracy: 0.6789\n",
      "Epoch 30/60\n",
      "7766/7766 - 1s - loss: 0.7063 - accuracy: 0.6832\n",
      "Epoch 31/60\n",
      "7766/7766 - 1s - loss: 0.7010 - accuracy: 0.6847\n",
      "Epoch 32/60\n",
      "7766/7766 - 1s - loss: 0.7042 - accuracy: 0.6819\n",
      "Epoch 33/60\n",
      "7766/7766 - 1s - loss: 0.6956 - accuracy: 0.6854\n",
      "Epoch 34/60\n",
      "7766/7766 - 1s - loss: 0.7014 - accuracy: 0.6822\n",
      "Epoch 35/60\n",
      "7766/7766 - 1s - loss: 0.7030 - accuracy: 0.6813\n",
      "Epoch 36/60\n",
      "7766/7766 - 1s - loss: 0.6958 - accuracy: 0.6843\n",
      "Epoch 37/60\n",
      "7766/7766 - 1s - loss: 0.6933 - accuracy: 0.6845\n",
      "Epoch 38/60\n",
      "7766/7766 - 1s - loss: 0.6975 - accuracy: 0.6817\n",
      "Epoch 39/60\n",
      "7766/7766 - 1s - loss: 0.7025 - accuracy: 0.6809\n",
      "Epoch 40/60\n",
      "7766/7766 - 1s - loss: 0.6948 - accuracy: 0.6830\n",
      "Epoch 41/60\n",
      "7766/7766 - 1s - loss: 0.6937 - accuracy: 0.6822\n",
      "Epoch 42/60\n",
      "7766/7766 - 1s - loss: 0.6874 - accuracy: 0.6847\n",
      "Epoch 43/60\n",
      "7766/7766 - 1s - loss: 0.6962 - accuracy: 0.6801\n",
      "Epoch 44/60\n",
      "7766/7766 - 1s - loss: 0.6841 - accuracy: 0.6844\n",
      "Epoch 45/60\n",
      "7766/7766 - 1s - loss: 0.6828 - accuracy: 0.6848\n",
      "Epoch 46/60\n",
      "7766/7766 - 1s - loss: 0.6829 - accuracy: 0.6844\n",
      "Epoch 47/60\n",
      "7766/7766 - 1s - loss: 0.6848 - accuracy: 0.6832\n",
      "Epoch 48/60\n",
      "7766/7766 - 1s - loss: 0.6809 - accuracy: 0.6844\n",
      "Epoch 49/60\n",
      "7766/7766 - 1s - loss: 0.6801 - accuracy: 0.6843\n",
      "Epoch 50/60\n",
      "7766/7766 - 1s - loss: 0.6778 - accuracy: 0.6856\n",
      "Epoch 51/60\n",
      "7766/7766 - 1s - loss: 0.6822 - accuracy: 0.6813\n",
      "Epoch 52/60\n",
      "7766/7766 - 1s - loss: 0.6765 - accuracy: 0.6843\n",
      "Epoch 53/60\n",
      "7766/7766 - 1s - loss: 0.6776 - accuracy: 0.6837\n",
      "Epoch 54/60\n",
      "7766/7766 - 1s - loss: 0.6779 - accuracy: 0.6821\n",
      "Epoch 55/60\n",
      "7766/7766 - 1s - loss: 0.6686 - accuracy: 0.6861\n",
      "Epoch 56/60\n",
      "7766/7766 - 1s - loss: 0.6712 - accuracy: 0.6852\n",
      "Epoch 57/60\n",
      "7766/7766 - 1s - loss: 0.6738 - accuracy: 0.6834\n",
      "Epoch 58/60\n",
      "7766/7766 - 1s - loss: 0.6733 - accuracy: 0.6827\n",
      "Epoch 59/60\n",
      "7766/7766 - 1s - loss: 0.6647 - accuracy: 0.6856\n",
      "Epoch 60/60\n",
      "7766/7766 - 1s - loss: 0.6773 - accuracy: 0.6819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x262c29437b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3161/1 - 0s - loss: 0.9969 - accuracy: 0.6314\n",
      "Loss: 0.8237606019997891, Accuracy: 0.6314457654953003\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the training data\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 561)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_test[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: [5]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction. The result should be 5 - STANDING\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'netron'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-db5d7b0e1219>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'netron'"
     ]
    }
   ],
   "source": [
    "import netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting netron\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/c5/ec4a58c4ded3a8dbdf011205b60d06168f8d3b4e574cf59c32bc992cf970/netron-3.5.2-py2.py3-none-any.whl (1.3MB)\n",
      "Installing collected packages: netron\n",
      "Successfully installed netron-3.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'smartphone_trained.h5' at http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "netron.start(\"smartphone_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
